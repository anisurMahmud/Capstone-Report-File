\chapter{Background Study} \label{ch:literature_review}


Emotions that incite individuals to write down certain words at particular times are what emotion detection is about. People often convey their feelings through texts, words. That's why it has been the topic of research for many. Researchers often try to create or innovate or perfect systems to better understand how emotions can be extracted in a meaningful way. Deep learning has also paved the way for researchers to further study this topic.
\section{Literature Review}

\subsection{Emotion Correlation Mining Through Deep Learning Models on Natural Language Text}
Xinzhi Wang et al.[1] introduced an embedded recursive neural network for improving emotion recognition, Long Short-Term Memory (LSTM) was used as a variant of RNNs. This method determines to do the potential and meaningful correlation among emotions from Web news. Tow deep neural network models, CNN-LSTM2 and CNN-LSTM-STACK are employed for emotion recognition. The data sets are collected from one of the most popular social platforms, news channel. Emotion correlation differs for different types datasets. In objective texts, some emotions be misinterpreted as love. Also, emotions are easily mistaken as anger. Yet, it achieved greater than 85\% and approaches 90\%.


\subsection{Topic-Enhanced Capsule Network for Multi-Label Emotion Classification}
Donghong Ji et al.[2] developed a capsule network which is effectively leveraging for multiple emotion prediction. This model consists of two components, a topic module and a capsule model. The topic module takes Bag of Words (BoW) as input via Variational Autoencoder (VAE) and learns latent topics and keywords. Then the capsule module captures encapsulated features for each emotion from low level to high level via three deep capsule layers. In the learning process, they pre-train the emotion module and co-train the entire part with a batch size of 16, both under early-stop strategy. Results on the benchmark data-sets showed that their method outperformed strong baselines by a large margin.



\subsection{An Experimental Analysis of Data Annotation Methodologies for Emotion Detection in Short Text Posted on Social Media}

Maria Krommyda et al.[3] proposed a hybrid rule-based algorithm that allows the acquisition of a dataset that is annotated with regard to the Plutchik's eight basic emotions. This technique is not focusing on the positive or negative opinions expressed but tries to determines the human emotion that is expressed. A total of 1.2 million annotated tweets were downloaded. Eighty percent of them were used as a training sample, 10\% as validation and 10\% as testing. The LSTM network was used and achieved 91.9\% accuracy. Yet, this system is weak to detect some particular emotion such as disgust and joy. But the overall performance of the system is quite significant. 

\subsection{Emotion and Sentiment Analysis of Tweet using BERT}

Anrea Chiorrini et al.[4] proposed two BERT-based architectures for text classification for sentiment and emotion recognition of twitter data with fine tuning. Two different datasets were used, on for emotion detection, the other for sentiment analysis. 80\% of the datasets were used to train the uncased and cased version of BERT. 92\% accuracy in sentiment analysis and 90\% accuracy in emotion analysis was obtained. However, the performance is not satisfactory because the performance of classifiers were not improved by tuning the final classification layer and the datasets used to train didnâ€™t have rich quality limiting the training process to only some parameters. Also there was an increment of validation loss after the first epoch due to overfitting.

\subsection{Fusion Approaches For Emotion Recognition From Speech Using Acoustic And Text-based Features}
Leonardo Pepino et al.[5] introduced different approaches for classifying emotions from speech using acoustic and text based features. Also determines to use word embeddings with BERT to show better performance than using Glove embeddings. For the text based model, BERT is to be used for data extraction from text with additional fine tuning. For the audio based model, pitch, jitter, shimmer, loudness, these features are to be extracted using openSMILE. Training of fusion models was done in 3 different ways: Cold-start, Pre-trained and Warm-start. The author in this study used fusion to merge two methods together. Rather than having individual programs for acoustic data and text based data, a single fusion based method was used to detect emotion from the dataset. And leads to significant improvements of approximately 16\% on both datasets relative to using the best single modality.

\subsection{Multimodal Sentiment Detection Based on Multi-channel Graph Neural Networks}
Xiaocui Yang et al.[6] proposed Multi-channel Graph Neural Networks with Sentiment-awareness (MGNNS) for image-text sentiment detection. MGNNS model for multimodal sentiment detection that consists of three modules: the encoding module, the multi-GNN module, and the multimodal interaction module. They conduct experiments on three multimodal sentiment datasets from social media platforms, MVSA-Single, MVSA-Multiple, and TumEmo, and compare our MGNNS model with a number of unimodal and multimodal approaches. Their model (MGNNS) is competitive with the other strong baseline models on the three datasets. The multimodal sentiment analysis models perform better than most of the unimodal sentiment analysis models on all three datasets. Finally, the TGNN unimodal model outperforms the HSAN multimodal model, indicating that the GNN has excellent performance in sentiment analysis.

\section{Problem Analysis}






