\chapter{Background Study} \label{ch:literature_review}


Emotions that incite individuals to write down certain words at particular times are what emotion detection is about. People often convey their feelings through texts, words. That's why it has been the topic of research for many. Researchers often try to create or innovate or perfect systems to better understand how emotions can be extracted in a meaningful way. Deep learning has also paved the way for researchers to further study this topic.
\section{Literature Review}

\subsection{Emotion Correlation Mining Through Deep Learning Models on Natural Language Text}
Xinzhi Wang et al.[1] introduced an embedded recursive neural network for improving emotion recognition, Long Short-Term Memory (LSTM) was used as a variant of RNNs. This method determines to do the potential and meaningful correlation among emotions from Web news. Two deep neural network models, CNN-LSTM2 and CNN-LSTM-STACK are employed for emotion recognition. The data sets are collected from one of the most popular social platforms, news channel. Emotion correlation differs for different types datasets. In objective texts, some emotions be misinterpreted as love. Also, emotions are easily mistaken as anger. Yet, it achieved greater than 85\% and approaches 90\%.


\subsection{Topic-Enhanced Capsule Network for Multi-Label Emotion Classification}
Donghong Ji et al.[2] developed a capsule network which is effectively leveraging for multiple emotion prediction. This model consists of two components, a topic module and a capsule model. The topic module takes Bag of Words (BoW) as input via Variational Autoencoder (VAE) and learns latent topics and keywords. Then the capsule module captures encapsulated features for each emotion from low level to high level via three deep capsule layers. In the learning process, they pre-train the emotion module and co-train the entire part with a batch size of 16, both under early-stop strategy. Results on the benchmark data-sets showed that their method outperformed strong baselines by a large margin.



\subsection{An Experimental Analysis of Data Annotation Methodologies for Emotion Detection in Short Text Posted on Social Media}

Maria Krommyda et al.[3] proposed a hybrid rule-based algorithm that allows the acquisition of a dataset that is annotated with regard to the Plutchik's eight basic emotions. This technique is not focusing on the positive or negative opinions expressed but tries to determines the human emotion that is expressed. A total of 1.2 million annotated tweets were downloaded. Eighty percent of them were used as a training sample, 10\% as validation and 10\% as testing. The LSTM network was used and achieved 91.9\% accuracy. Yet, this system is weak to detect some particular emotion such as disgust and joy. But the overall performance of the system is quite significant. 

\subsection{Emotion and Sentiment Analysis of Tweet using BERT}

Anrea Chiorrini et al.[4] proposed two BERT-based architectures for text classification for sentiment and emotion recognition of twitter data with fine tuning. Two different datasets were used, on for emotion detection, the other for sentiment analysis. 80\% of the datasets were used to train the uncased and cased version of BERT. 92\% accuracy in sentiment analysis and 90\% accuracy in emotion analysis was obtained. However, the performance is not satisfactory because the performance of classifiers were not improved by tuning the final classification layer and the datasets used to train didn’t have rich quality limiting the training process to only some parameters. Also there was an increment of validation loss after the first epoch due to overfitting.

\subsection{Fusion Approaches For Emotion Recognition From Speech Using Acoustic And Text-based Features}
Leonardo Pepino et al.[5] introduced different approaches for classifying emotions from speech using acoustic and text based features. Also determines to use word embeddings with BERT to show better performance than using Glove embeddings. For the text based model, BERT is to be used for data extraction from text with additional fine tuning. For the audio based model, pitch, jitter, shimmer, loudness, these features are to be extracted using openSMILE. Training of fusion models was done in 3 different ways: Cold-start, Pre-trained and Warm-start. The author in this study used fusion to merge two methods together. Rather than having individual programs for acoustic data and text based data, a single fusion based method was used to detect emotion from the dataset. And leads to significant improvements of approximately 16\% on both datasets relative to using the best single modality.

\subsection{Multimodal Sentiment Detection Based on Multi-channel Graph Neural Networks}
Xiaocui Yang et al.[6] proposed Multi-channel Graph Neural Networks with Sentiment-awareness (MGNNS) for image-text sentiment detection. MGNNS model for multimodal sentiment detection that consists of three modules: the encoding module, the multi-GNN module, and the multimodal interaction module. They conduct experiments on three multimodal sentiment datasets from social media platforms, MVSA-Single, MVSA-Multiple, and TumEmo, and compare our MGNNS model with a number of unimodal and multimodal approaches. Their model (MGNNS) is competitive with the other strong baseline models on the three datasets. The multimodal sentiment analysis models perform better than most of the unimodal sentiment analysis models on all three datasets. Finally, the TGNN unimodal model outperforms the HSAN multimodal model, indicating that the GNN has excellent performance in sentiment analysis.

\subsection{Emotion Detection for Social Robots Based on NLP Transformers and an Emotion Ontology}
Wilfredo Graterol et al.[7] proposed a framework to allow social robots to detect emotions and store this information in an ontology-based repository, based on EMONTO (an EMotion ONTOlogy). Framework relies on a speech-to-text converter based on the Google Application Programming Interface (API). Then, a neural network to label the emotions in texts based on NLP transformers; and EMONTO, an ontology to represent emotions integrated with an ontology. They used Attention-based transformers architecture, which is inspired by the encoder–decoder architecture used for sequence to sequence (Seq2seq) tasks. They have some issues to detect emotion and process it during the training session. Their system's framework is barely flexible. However, the performance is not satisfactory because the system is not that robust.

\subsection{Emotion Analysis for predicting the emotion labels using Machine Learning approaches}
Tanya Sharma et al.[8] proposed to compare the different machine learning algorithm (LR,Naive Bayes, LSTM and GRU) to detect positive and negative intention from text. For RNN (LSTM and GRU), this model is trained that results an emotion for a provided input text data. The result will predict emotion label. This model includes 3 different modules: data Preparation, building our Model and Training our model. Also, Dataset used in this model contains thousands of tweets collected from twitter, sentiment for every tweet is labelled negative, positive and neutral respectively for LR and Naive Bayes. The accuracy rate of LSTM 74\%, GRU accuracy rate 68\%, LR accuracy rate 70\% and Naive Bayes accuracy rate 60\%. However, we can say that LSTM performs better in terms of accuracy then others to detect emotions.

\section{Problem Analysis}
Researchers often face problems regarding emotion detection. There are challenges to face. Hao Fei et al topic enhanced capsules to support their theory but it was harder to provide accurate statistical data to back up their argument. Also finding the right tool to conduct research can be troublesome at times. Andrea Chiorrini et al used BERT for sentiment analysis. But a program of such caliber is not always easy for fine tuning. Classifier performance was the same as before. Due to already heavy optimisation in the program, researchers use it as it is. Leonardo Pepino et al used fusion to merge two methods together to support both acoustic data and text based data. But when combining different datasets together, good improvements may be achieved but it also requires huge amounts of data to properly train the program to provide accurate results every time. Gathering huge amounts of different data is not always effortless. Xinzhi Wang et al conducted the research using CNN methods but faced a problem quite often. It is often hard to differentiate emotion from love and anger. A lot of data is often mistaken as love and anger. And it is due to the evolution of language which makes emotion detection harder than before.


In this chapter we have summarized some of the literature reviews. Where the researcher's topic or which field is being explored, what are the main issues, what kind of method, datasets, has been used is described. And also researchers often face problems regarding emotion detection, the kind of problem they face is explored.







